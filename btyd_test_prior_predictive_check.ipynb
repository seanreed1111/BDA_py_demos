{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "btyd-test-prior-predictive-check.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seanreed1111/BDA_py_demos/blob/master/btyd_test_prior_predictive_check.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "see also: \n",
        "- https://www.briancallander.com/posts/customer_lifetime_value/pareto-nbd.html\n",
        "- https://www.briancallander.com/posts/customer_lifetime_value/recency_frequency.Rmd\n",
        "- https://www.briancallander.com/posts/customer_lifetime_value/recency_frequency.html\n",
        "- https://github.com/mplatzer/BTYDplus/blob/master/R/pareto-nbd-mcmc.R\n",
        "- https://cran.r-project.org/web/packages/BTYD/BTYD.pdf\n",
        "- https://github.com/mplatzer/BTYDplus\n",
        "\n"
      ],
      "metadata": {
        "id": "eQA5kIjjxpuy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# installlation required\n",
        "!pip install pyro-ppl=='1.8.0'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uY7dTQrGT7o2",
        "outputId": "45948505-9b5a-49f0-9aac-9855de59f9c9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyro-ppl==1.8.0 in /usr/local/lib/python3.7/dist-packages (1.8.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl==1.8.0) (1.21.5)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl==1.8.0) (1.10.0+cu111)\n",
            "Requirement already satisfied: pyro-api>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl==1.8.0) (0.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl==1.8.0) (3.3.0)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl==1.8.0) (4.63.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.9.0->pyro-ppl==1.8.0) (3.10.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id = \"7\"></a><br>\n",
        "# LIBRARIES"
      ],
      "metadata": {
        "id": "FGj7ZXnYisy4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import datetime as dt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import logging\n",
        "from scipy.stats import expon, poisson, uniform, lognorm\n",
        "\n",
        "from numpy.random import Generator, PCG64\n",
        "numpy_randomGen = Generator(PCG64(seed=1))\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.distributions import constraints\n",
        "from torch import tensor\n",
        "\n",
        "import pyro\n",
        "import pyro.distributions as dist\n",
        "from pyro.infer import SVI,Trace_ELBO\n",
        "from pyro.infer.autoguide  import AutoMultivariateNormal, AutoNormal, init_to_mean\n",
        "from pyro.optim import ClippedAdam\n",
        "\n",
        "# Set matplotlib settings\n",
        "%matplotlib inline\n",
        "plt.style.use('default')\n",
        "plt.rcParams['figure.figsize'] = [8, 4]\n",
        "import warnings \n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-15T11:59:37.295326Z",
          "iopub.execute_input": "2021-09-15T11:59:37.295724Z",
          "iopub.status.idle": "2021-09-15T11:59:53.721615Z",
          "shell.execute_reply.started": "2021-09-15T11:59:37.295626Z",
          "shell.execute_reply": "2021-09-15T11:59:53.720577Z"
        },
        "trusted": true,
        "id": "aKznBx1oisy5"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s describe the model first by simulation. \n",
        "\n",
        "Suppose we have a company that is 2 years old and a total of 2000 customers, C, that have made at least one purchase from us. \n",
        "\n",
        "We’ll assume a linear rate of customer acquisition, so that the first purchase date is simply a uniform random variable over the 2 years of the company existance. These assumptions are just to keep the example concrete, and are not so important for understanding the model."
      ],
      "metadata": {
        "id": "M8XPw-evgBdu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each customer c∈C is assumed to have a certain lifetime, τc, starting on their join-date. \n",
        "\n",
        "During their lifetime, they will purchase at a constant rate, λc, so that they will make k∼Poisson(tλc) purchases over a time-interval t. \n",
        "\n",
        "Once their lifetime is over, they will stop purchasing. We only observe the customer for Tc units of time, and this observation time can be either larger or smaller than the lifetime, τc. \n",
        "\n",
        "Since we don’t observe τc itself, we will assume it follows an exponential distribution, i.e. τc∼Exp(μc)."
      ],
      "metadata": {
        "id": "MjtZTqtPgajd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logging.basicConfig(level=logging.DEBUG)"
      ],
      "metadata": {
        "id": "BvV5LWUU8kNr"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_start_dates(n, max_number_of_periods):\n",
        "  '''\n",
        "  returns an array of n start dates in interval [0, max_number_of_periods)\n",
        "  \n",
        "  inputs \n",
        "  int n: number of customers to generate\n",
        "  int max_number_of_periods: max number of periods customer can be observed in simulation\n",
        "\n",
        "  output: \n",
        "  start_date[n]: starting period of customer n, starting from 0\n",
        "  '''\n",
        "  return np.random.default_rng(1).integers(low=0, high=max_number_of_periods, size=n)"
      ],
      "metadata": {
        "id": "C5YZkVe7-WwF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customer_enrollment_dates = create_start_dates(n=10, max_number_of_periods=200)\n",
        "customer_enrollment_dates"
      ],
      "metadata": {
        "id": "ooVgnLGF-jP-",
        "outputId": "6708eba2-b7b9-48d5-8798-94b93dd1dae2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 94, 102, 151, 190,   6,  28, 164, 189,  49,  62])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions"
      ],
      "metadata": {
        "id": "U46ULj8YmIq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FROZEN DEFINITION\n",
        "# def simulate_purchases(*,T, obs_end_date, mean_customer_lifetime, mean_period_between_purchases, var_customer_lifetime = None, var_period_between_purchases = None  ):\n",
        "#   '''\n",
        "#   input: \n",
        "#   T: customer enrollment date\n",
        "#   obs_start_date: We only observe customer behavior on the open interval [obs_start_date, obs_end_date)\n",
        "#   obs_end_date:  We only observe customers behavior on the open interval [obs_start_date, obs_end_date)\n",
        "\n",
        "#   mean_customer_lifetime: mean of customer lifetime, in periods\n",
        "#   var_customer_lifetime: var of customer lifetime\n",
        "#   mean_period_between_purchases: mean period between purchases\n",
        "#   var_period_between_purchases: var of period between purchases\n",
        "\n",
        "#   output:\n",
        "#   k: number of purchases\n",
        "#   T: observation time. This is the length of time they have been a customer\n",
        "#   tau: actual (latent) lifetime for this customer (drawn from exponential distribution with scale=mean_customer_lifetime)\n",
        " \n",
        "#   '''\n",
        "#   from scipy.stats import expon\n",
        "\n",
        "#   assert min(mean_customer_lifetime, mean_period_between_purchases) > 0, \"mean lifetime and mean period between purchases must both be > 0\"\n",
        "  \n",
        "#   tau = expon.rvs(scale=mean_customer_lifetime) # actual lifetime for this customer\n",
        "#   t, k = T, 0 \n",
        "#   wait = expon.rvs(scale=mean_period_between_purchases) # waiting time between purchases\n",
        "#   while ((t + wait) < min(obs_end_date, T + tau)): # rewrite this while loop it is confusing!\n",
        "#     t = t + wait\n",
        "#     k = k + 1\n",
        "#     logging.info(t,k,tau, wait)\n",
        "#     wait = expon.rvs(scale=mean_period_between_purchases)\n",
        "\n",
        "#   return  T, k, tau, t  #final value of t is time of last purchased\n",
        "\n",
        "# simulate_purchases_vec = np.vectorize(simulate_purchases)"
      ],
      "metadata": {
        "id": "Tu6rutRvGic3"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customer_enrollment_dates"
      ],
      "metadata": {
        "id": "fAyNcEvnOHEY",
        "outputId": "e7f373c4-9eab-4ad7-dafc-8d95f6c567d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 94, 102, 151, 190,   6,  28, 164, 189,  49,  62])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "simulate_purchases(T=94, obs_end_date=200, mean_customer_lifetime=100, mean_period_between_purchases=8)"
      ],
      "metadata": {
        "id": "tvbQ9KeEPIk-",
        "outputId": "51db3dce-7c2a-4e13-ee54-081f9c138de0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(94, 0, 1.3216269927743665, 94)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "purchases = simulate_purchases_vec(T=customer_enrollment_dates, obs_end_date=200, mean_customer_lifetime=100, mean_period_between_purchases=8)\n",
        "purchases"
      ],
      "metadata": {
        "id": "jojIe57uNfWT",
        "outputId": "5c683d59-7af1-403e-ea2d-4618baf125f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 94, 102, 151, 190,   6,  28, 164, 189,  49,  62]),\n",
              " array([10,  9,  3,  0,  0,  1,  7,  2, 22,  9]),\n",
              " array([ 76.8534581 , 327.38212196,  24.11419825,  51.80330271,\n",
              "          0.91746579,  32.38028258,  98.30495392,  56.94470469,\n",
              "        144.77520602,  52.32215686]),\n",
              " array([161.92819107, 198.04510953, 173.18596593, 190.        ,\n",
              "          6.        ,  44.25179635, 192.16778106, 199.75314084,\n",
              "        181.54970042, 114.3055459 ]))"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def simulate_purchases(*,T, obs_end_date, mean_customer_lifetime, mean_period_between_purchases, var_customer_lifetime = None, var_period_between_purchases = None  ):\n",
        "  '''\n",
        "  input: \n",
        "  T: customer enrollment date\n",
        "  obs_start_date: We only observe customer behavior on the open interval [obs_start_date, obs_end_date)\n",
        "  obs_end_date:  We only observe customers behavior on the open interval [obs_start_date, obs_end_date)\n",
        "\n",
        "  mean_customer_lifetime: mean of customer lifetime, in periods\n",
        "  var_customer_lifetime: var of customer lifetime\n",
        "  mean_period_between_purchases: mean period between purchases\n",
        "  var_period_between_purchases: var of period between purchases\n",
        "\n",
        "  output:\n",
        "  k: number of purchases\n",
        "  T: observation time. This is the length of time they have been a customer\n",
        "  tau: actual (latent) lifetime for this customer (drawn from exponential distribution with scale=mean_customer_lifetime)\n",
        " \n",
        "  '''\n",
        "  from scipy.stats import expon\n",
        "\n",
        "  assert mean_customer_lifetime > 0 and mean_period_between_purchases > 0, \"mean lifetime and mean period between purchases must both be > 0\"\n",
        "  \n",
        "  tau = expon.rvs(scale=mean_customer_lifetime) # actual lifetime for this customer\n",
        "  t, k = T, 0 \n",
        "  wait = expon.rvs(scale=mean_period_between_purchases) # waiting time between purchases\n",
        "  while ((t + wait) < min(obs_end_date, T + tau)): \n",
        "    t = t + wait\n",
        "    k = k + 1\n",
        "    logging.info(t,k,tau, wait)\n",
        "    wait = expon.rvs(scale=mean_period_between_purchases)\n",
        "\n",
        "  return  T, k, tau, t  #final value of t is time of last purchased\n",
        "\n",
        "simulate_purchases_vec = np.vectorize(simulate_purchases)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wYOxTjogN8C0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_customer_df(*,n, obs_end_date, mean_customer_lifetime, mean_period_between_purchases, var_customer_lifetime = None, var_period_between_purchases = None):\n",
        "  '''\n",
        "  output: \n",
        "    dataframe[['k','T','tau','t']] where\n",
        "\n",
        "  k: number of purchases\n",
        "  T: observation time. This is the length of time they have been a customer\n",
        "  tau: actual lifetime for this customer drawn from exponential distribution with scale=mean_customer_lifetime\n",
        "  t_recency: time since customer's last purchase\n",
        "  '''\n",
        "  T =  create_start_dates(10, 200)\n"
      ],
      "metadata": {
        "id": "QkKlXzQDaJu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# def create_df(*,n, mean_lifetime, mean_period_between_purchases, max_obs_time=200, t_measurement=None):\n",
        "#   '''\n",
        "#   input: \n",
        "#   mean_lifetime\n",
        "#   mean_period_between_purchases\n",
        "#   n: number of customers,\n",
        "#   max_obs_time: maximum time the customer could have been observed\n",
        "#   t_measurement: time of measurement. Sets to max_obs_time if None\n",
        "\n",
        "#   output: \n",
        "#   dataframe[['k','T','tau','t']] where\n",
        "\n",
        "#   k: number of purchases\n",
        "#   T: observation time. This is the length of time they have been a customer\n",
        "#   tau: actual lifetime for this customerm drawn from exponential distribution with scale=mean_customer_lifetime\n",
        "#   t_recency: time since customer's last purchase\n",
        "#   '''\n",
        "#   if t_measurement is None: \n",
        "#     t_measurement = max_obs_time\n",
        "  \n",
        "#   T = create_T(n, max_obs_time)\n",
        "#   result = simulate_purchases_vec(T, t_measurement, mean_lifetime, mean_period_between_purchases)\n",
        "\n",
        "#   return pd.DataFrame(result, index=['k','T','tau','t_recency']).T "
      ],
      "metadata": {
        "id": "315gCYPzNX33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Model Definition"
      ],
      "metadata": {
        "id": "GetrCeCLlpN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_test(t, T, k, prior_only=False):\n",
        "  '''\n",
        "  input:\n",
        "  vector t (nx1)  = time since most recent purchase (recency)\n",
        "  vector T (nx1) = total observation time\n",
        "  vector k (nx1) = number of purchases observed (k must be >= 2)\n",
        "\n",
        "  n, etau_alpha, etau_beta, Lambda_alpha, Lambda_beta are scalars\n",
        "  n = number of customers\n",
        "  etau_alpha, etau_beta are priors for etau\n",
        "  Lambda_alpha, Lambda_beta are priors for Lambda\n",
        "  '''\n",
        "  assert torch.all(k >=2.), \"There are illegal values of k. k must be >= 2\"\n",
        "\n",
        "  def loglik(Lambda, mu, t, T, k):\n",
        "    target = k * torch.log(Lambda) - torch.log(Lambda + mu)\n",
        "    n = Lambda.size(0)\n",
        "    for i in range(n):\n",
        "      target  = target + torch.logaddexp(torch.log(Lambda[i]) - (Lambda[i] + mu[i]) * T[i],\n",
        "                                        torch.log(mu[i]) - (Lambda[i] + mu[i]) * t[i]\n",
        "                                        )\n",
        "    return target\n",
        "  \n",
        "  tau_alpha = pyro.sample('tau_alpha', dist.Uniform(-1,1))\n",
        "  tau_beta = pyro.sample('tau_beta', dist.Uniform(-2,2))\n",
        "  Lambda_alpha = pyro.sample('Lambda_alpha', dist.Uniform(-3,3))\n",
        "  Lambda_beta = pyro.sample('Lambda_beta', dist.Uniform(-4,4))\n",
        "\n",
        "  if not prior_only:\n",
        "    with pyro.plate(\"data\", t.size(0)):\n",
        "      tau  = pyro.sample('tau', dist.Gamma(tau_alpha, tau_beta))\n",
        "      mu = 1./tau\n",
        "      Lambda = pyro.sample('Lambda', dist.Gamma(Lambda_alpha, Lambda_beta))\n",
        "    pyro.factor('loglik', loglik(Lambda, mu, t, T, k))"
      ],
      "metadata": {
        "id": "I8ImhM3cicce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## original model"
      ],
      "metadata": {
        "id": "oIsYOACkk45H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_one(t, T, k, prior_only=False):\n",
        "  '''\n",
        "  input:\n",
        "  vector t (nx1)  = time since most recent purchase (recency)\n",
        "  vector T (nx1) = total observation time\n",
        "  vector k (nx1) = number of purchases observed (k must be >= 2)\n",
        "\n",
        "  n, etau_alpha, etau_beta, Lambda_alpha, Lambda_beta are scalars\n",
        "  n = number of customers\n",
        "  etau_alpha, etau_beta are priors for etau\n",
        "  Lambda_alpha, Lambda_beta are priors for Lambda\n",
        "  '''\n",
        "  assert torch.all(k >=2.), \"There are illegal values of k. k must be >= 2\"\n",
        "\n",
        "  def loglik(Lambda, mu, t, T, k):\n",
        "    target = k * torch.log(Lambda) - torch.log(Lambda + mu)\n",
        "    n = Lambda.size(0)\n",
        "    for i in range(n):\n",
        "      target  = target + torch.logaddexp(torch.log(Lambda[i]) - (Lambda[i] + mu[i]) * T[i],\n",
        "                                        torch.log(mu[i]) - (Lambda[i] + mu[i]) * t[i]\n",
        "                                        )\n",
        "    return target\n",
        "  \n",
        "  # etau_alpha = pyro.sample('etau_alpha', dist.)\n",
        "  # etau_beta = pyro.sample('etau_beta', dist)\n",
        "  # Lambda_alpha = pyro.sample('Lambda_alpha', dist)\n",
        "  # Lambda_beta = pyro.sample('Lambda_beta', dist)\n",
        "\n",
        "  with pyro.plate(\"data\", t.size(0)):\n",
        "    etau  = pyro.sample('etau', dist.InverseGamma(etau_alpha, etau_beta))\n",
        "    mu = 1./etau\n",
        "    Lambda = pyro.sample('Lambda', dist.Gamma(Lambda_alpha, Lambda_beta))\n",
        "\n",
        "  if prior_only:\n",
        "    pyro.factor('loglik', loglik(Lambda, mu, t, T, k))\n",
        "  else:\n",
        "    pyro.factor('zero', 0)"
      ],
      "metadata": {
        "id": "UbZZAZQJfbb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zJX96GcqiaRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## create data"
      ],
      "metadata": {
        "id": "IdaeP-s_k_zr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = create_df(n=100, mean_lifetime =100, mean_period_between_purchases =1)\n",
        "data = data[data['k'] >= 2.] # multiple purchases only\n",
        "data"
      ],
      "metadata": {
        "id": "yeiHkP2t_Jxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t, T, k = tensor(data['t_recency'].values), tensor(data['T'].values), tensor(data['k'].values)"
      ],
      "metadata": {
        "id": "7AvwQoWQmod6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UI-Cb0TW_NXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perform MCMC"
      ],
      "metadata": {
        "id": "VA5Aa_Q1fkE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyro.infer import MCMC, NUTS\n",
        "model = model_test\n",
        "nuts_kernel = NUTS(model)\n",
        "mcmc = MCMC(nuts_kernel, num_samples=1000, warmup_steps=250)\n",
        "\n",
        "mcmc.run(t, T, k, prior_only=True)"
      ],
      "metadata": {
        "id": "qN0a8ZjMa4H4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hmc_samples = {k: v.detach().cpu().numpy() for k, v in mcmc.get_samples().items()}\n",
        "hmc_samples.keys()"
      ],
      "metadata": {
        "id": "k5sSaGJthRW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key in hmc_samples.keys():\n",
        "  sns.kdeplot(data = hmc_samples[key])"
      ],
      "metadata": {
        "id": "7CBnPcwahRS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Centered BTYD"
      ],
      "metadata": {
        "id": "XZxpKYo-fWZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# https://www.briancallander.com/posts/customer_lifetime_value/models/rf.stan\n",
        "# data_hyperpriors <- list(\n",
        "#   log_life_mean_mu = log(31),\n",
        "#   log_life_mean_sigma = 0.7,\n",
        "#   log_life_scale_sigma = 0.8,\n",
        "\n",
        "#   log_lambda_mean_mu = log(1 / 14),\n",
        "#   log_lambda_mean_sigma = 0.3,\n",
        "#   log_lambda_scale_sigma = 0.5\n",
        "# )\n",
        "data {\n",
        "  int<lower = 1> n;       // number of customers\n",
        "  vector<lower = 0>[n] t; // time to most recent purchase\n",
        "  vector<lower = 0>[n] T; // total observation time\n",
        "  vector<lower = 0>[n] k; // number of purchases observed\n",
        "\n",
        "  // user-specified parameters\n",
        "  real<lower = 0> etau_mean_alpha;\n",
        "  real<lower = 0> etau_mean_beta;\n",
        "  real<lower = 0> etau_sd_alpha;\n",
        "  real<lower = 0> etau_sd_beta;\n",
        "\n",
        "  real<lower = 0> lambda_mean_alpha;\n",
        "  real<lower = 0> lambda_mean_beta;\n",
        "  real<lower = 0> lambda_sd_alpha;\n",
        "  real<lower = 0> lambda_sd_beta;\n",
        "}\n",
        "\n",
        "parameters {\n",
        "  vector<lower = 0>[n] lambda; // purchase rate\n",
        "  vector<lower = 0>[n] etau;   // expected mean lifetime\n",
        "\n",
        "  vector<lower = 0>[n] etau_mean; // mean expected life span\n",
        "  vector<lower = 0>[n] etau_sd;\n",
        "  vector<lower = 0>[n] lambda_mean; // mean purchase rate\n",
        "  vector<lower = 0>[n] lambda_sd;\n",
        "\n",
        "}\n",
        "\n",
        "transformed parameters {\n",
        "  vector<lower = 0>[n] etau_beta = etau_mean;\n",
        "  vector<lower = 0>[n] etau_alpha = etau_sd;\n",
        "  vector<lower = 0>[n] lambda_beta = lambda_mean ./ (lambda_sd .* lambda_sd);\n",
        "  vector<lower = 0>[n] lambda_alpha = lambda_beta .* lambda_mean;\n",
        "\n",
        "  vector<lower = 0>[n] mu = 1.0 ./ etau;\n",
        "}\n",
        "\n",
        "model {\n",
        "  // hyperpriors\n",
        "  etau_mean ~ gamma(etau_mean_alpha, etau_mean_beta);\n",
        "  etau_sd ~ gamma(etau_sd_alpha, etau_sd_beta);\n",
        "\n",
        "  lambda_mean ~ gamma(lambda_mean_alpha, lambda_mean_beta);\n",
        "  lambda_sd ~ gamma(lambda_sd_alpha, lambda_sd_beta);\n",
        "\n",
        "  // priors\n",
        "  etau ~ inv_gamma(etau_alpha, etau_beta);\n",
        "  lambda ~ gamma(lambda_alpha, lambda_beta);\n",
        "\n",
        "  // likelihood\n",
        "  target += k .* log(lambda) - log(lambda + mu);\n",
        "  for (i in 1:n) {\n",
        "    target += log_sum_exp(\n",
        "      log(lambda[i]) - (lambda[i] + mu[i]) .* T[i],\n",
        "      log(mu[i]) - (lambda[i] + mu[i]) .* t[i]\n",
        "    );\n",
        "  }\n",
        "}\n"
      ],
      "metadata": {
        "id": "Sme-1n-EhRG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-centered BTYD"
      ],
      "metadata": {
        "id": "nUSy4aCHfbpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# non-centered BTYD\n",
        "# https://www.briancallander.com/posts/customer_lifetime_value/recency_frequency.html\n",
        "# https://www.briancallander.com/posts/customer_lifetime_value/models/rf_noncentred.stan\n",
        "\n",
        "data {\n",
        "  int<lower = 1> n;       // number of customers\n",
        "  vector<lower = 0>[n] t; // time between first and last purchase\n",
        "  vector<lower = 0>[n] T; // total observation time\n",
        "  vector<lower = 0>[n] k; // number of purchases\n",
        "\n",
        "  // hyperparameters for the expected lifetime\n",
        "  real log_life_mean_mu;\n",
        "  real<lower = 0> log_life_mean_sigma;\n",
        "  // hyperparameter for scale of customer-level lifetime effects\n",
        "  real<lower = 0> log_life_scale_sigma;\n",
        "\n",
        "  // hyperparameters for the expected purchase rate\n",
        "  real log_lambda_mean_mu;\n",
        "  real<lower = 0> log_lambda_mean_sigma;\n",
        "  // hyperparameter for scale of customer-level purchase-rate effects\n",
        "  real<lower = 0> log_lambda_scale_sigma;\n",
        "\n",
        "  // flag whether to only sample from the prior\n",
        "  // to draw from the prior-predictive distribution: prior_only = 1\n",
        "  // to draw from the posterior distribution: prior_only = 0\n",
        "  int<lower = 0, upper = 1> prior_only;\n",
        "}\n",
        "\n",
        "transformed data {\n",
        "  vector<lower = 0, upper = 0>[2] zero = rep_vector(0, 2);\n",
        "  vector[2] J = [-1, 1]';\n",
        "  vector[2] m = [log_life_mean_mu, log_lambda_mean_mu]';\n",
        "  matrix<lower = 0>[2, 2] m_sigma = diag_matrix([log_life_mean_sigma, log_lambda_mean_sigma]');\n",
        "  matrix<lower = 0>[2, 2] s_sigma = diag_matrix([log_life_scale_sigma, log_lambda_scale_sigma]');\n",
        "}\n",
        "\n",
        "parameters {\n",
        "  row_vector[2] log_centres;\n",
        "  vector<lower = 0>[2] scales;\n",
        "  matrix[n, 2] customer; // customer-level effects\n",
        "}\n",
        "\n",
        "transformed parameters {\n",
        "  matrix<lower = 0>[n, 2] theta = exp(\n",
        "    diag_post_multiply(\n",
        "      rep_matrix(log_centres, n) + diag_post_multiply(customer, scales),\n",
        "      J\n",
        "    )\n",
        "  ); // (mu, lambda)\n",
        "}\n",
        "\n",
        "model {\n",
        "  // priors\n",
        "  log_centres ~ multi_normal_cholesky(m, m_sigma);\n",
        "  scales ~ multi_normal_cholesky(zero, s_sigma);\n",
        "\n",
        "  for (i in 1:n) {\n",
        "\n",
        "    customer[i, ] ~ std_normal();\n",
        "\n",
        "    // likelihood\n",
        "    if (prior_only == 0) {\n",
        "      target += log_sum_exp(\n",
        "        log(theta[i, 2]) - (theta[i, 2] + theta[i, 1]) .* T[i],\n",
        "        log(theta[i, 1]) - (theta[i, 2] + theta[i, 1]) .* t[i]\n",
        "      );\n",
        "    }\n",
        "  }\n",
        "\n",
        "  if (prior_only == 0) {\n",
        "    target += k .* log(theta[, 2]) - log(theta[, 2] + theta[, 1]);\n",
        "  }\n",
        "\n",
        "}\n"
      ],
      "metadata": {
        "id": "Ro27nMERhRC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Z0rsJXyYhQ-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FH8phAQghQ6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zEmNp40EhQ08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "flVVOL4xhQv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wdwtKGxghQoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "z-qcdufPhQd4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}